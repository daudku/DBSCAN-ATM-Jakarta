{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[1] Import Modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from PIL import Image\n",
    "from pylab import rcParams\n",
    "\n",
    "df_saldo = pd.read_csv('ReplenishTrx.csv')\n",
    "print (\"Shape of the DataFrame: \", df_saldo.shape)\n",
    "\n",
    "#Select Top 3 Data\n",
    "df_saldo.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.5        1.        ]\n",
      " [0.         0.         0.5        1.        ]\n",
      " [0.         0.         0.51782531 1.        ]\n",
      " ...\n",
      " [0.51782531 0.         0.         1.        ]\n",
      " [0.5        0.         0.         1.        ]\n",
      " [0.5        0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, 280))\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#[2] Read CSV\n",
    "\n",
    "df_saldo = pd.read_csv('ReplenishTrx.csv')\n",
    "print (\"Shape of the DataFrame: \", df_saldo.shape)\n",
    "df_saldo.head(3) \n",
    "\n",
    "#Selecting the boundaries of the map from lattitude and longitude \n",
    "# L = lower\n",
    "# u = Upper\n",
    "llon=106.603905\n",
    "ulon=107.094555\n",
    "llat=-6.516244\n",
    "ulat=-6.023535\n",
    " \n",
    "print (\"Shape of the DataFrame after selecting: \", df_saldo.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Get Data\n",
    "df_saldo_clus = df_saldo[[ \"Longitude\", \"Latitude\"]]\n",
    "df_saldo_clus = Standardscaler().fit_transform(df_saldo_clus)\n",
    "\n",
    "#Compute DBSCAN\n",
    "_eps = 0.2\n",
    "_min_samp = 10\n",
    "db = DBSCAN(eps=_eps, min_samples= _min_samp, n_jobs=-l).fit(saldo_df_clus)\n",
    "\n",
    "labels = db.labels_\n",
    "saldo_df[\"ClusterDBSCAN\"]=labels\n",
    "\n",
    "\n",
    "#Export cluster to CSV\n",
    "saldo_df.to_csv(\"DATA\\\\DBSCAN \"+str(_eps)+\" \"+str(_min_samp)+\".csv\" index=False)\n",
    "\n",
    "#Number of clusters in tabeLs, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "clusterNum = len (set(labels))\n",
    "n_noise_ = list(labels).count(-l)\n",
    "\n",
    "#Print cLusters, noise, siLhoette score, timestamp\n",
    "if n_clusters > 0:\n",
    "    print(str(_eps) + ',' + str(_min_samp) + ',' + str(n_clusters_)\n",
    "        + ',' +  str(n_noise_) + ','\n",
    "        + str(metrics.silhouette_score(saldo_df_clus, labels, metric=\"euclidean\",n_jobs=-l))\n",
    "        + str(datetime.datetime.now()) )\n",
    "else:\n",
    "\tprint(str(_eps) + ',' + str(_min_samp) + ',' + str(n_clusters_)\n",
    "\t    + str(n_noise_)\t+ ',' + str(datetime.datetime.now()) )  \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import File\n",
    "saldo_df = pd.read_csv(\"DATA\\\\DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".csv\")      \n",
    "saldo_df = saldo_df.merge(pd.DataFrame({'CountReplenish':saldo_df.groupby(['MachineGroupCode', 'Longitude','Latitude','ClusterDBSCAN'])['MachineGroupCode'].count()}), left_on=['MachineGroupCode', 'Longitude','Latitude','ClusterDBSCAN'], right_index=True)\n",
    "saldo_df = saldo_df.drop('Id', 1)\n",
    "saldo_df = saldo_df.drop('DateReplenish', 1)\n",
    "saldo_df = saldo_df.drop('MachineCode', 1)\n",
    "saldo_df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "#Create map\n",
    "my_map = Basemap(llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "    urcrnrlon=ulon, urcrnrlat=ulat)\n",
    "my_map.arcgisimage(service='World_Street_Map', xpixels = 3000)\n",
    "\n",
    "labels = saldo_df[\"ClusterDBSCAN\"].to_numpy()  \n",
    "realClusterNum=len(set(labels)) - (1 if -1 in labels else 0) \n",
    "unique_labels = set(labels)\n",
    "\n",
    "# Create color cluster\n",
    "colors = plt.get_cmap('hsv')(np.linspace(0.0, 1.0, len(unique_labels)))\n",
    "\n",
    "#Visualization\n",
    "for clust_number in unique_labels: \n",
    "    c = (([0.4,0.4,0.4]) if clust_number == -1 else colors[clust_number])\n",
    "    clust_set = saldo_df[saldo_df.ClusterDBSCAN == clust_number]  \n",
    "    my_map.scatter(clust_set.Longitude, clust_set.Latitude, color =c,  marker='o', s= (clust_set.CountReplenish /100) +3 ,alpha = 0.65)\n",
    "    \n",
    "    if clust_number != -1:\n",
    "        cenx=np.mean(clust_set.Longitude) \n",
    "        ceny=np.mean(clust_set.Latitude) \n",
    "        plt.text(cenx,ceny,str(clust_number), fontsize=3, color=c,\n",
    "                path_effects=[path_effects.withStroke(linewidth=0.3, foreground=\"w\")])\n",
    "\n",
    "#Save Image\n",
    "plt.title(r\"ATM's in Jakarta Clustered : EPS=\"+str(_eps)+\", MinSamples=\"+str(_min_samp), fontsize=14)        \n",
    "plt.savefig(\"VISUALIZATION\\\\DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".png\", dpi=400)\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame:  (153964, 6)\n",
      "Shape of the DataFrame after selecting:  (153964, 6)\n"
     ]
    }
   ],
   "source": [
    "#[3] Clustering DBSCAN \n",
    "\n",
    "#Get Data\n",
    "df_saldo_clus = df_saldo[[ \"Longitude\", \"Latitude\"]]\n",
    "df_saldo_clus = StandardScaler().fit_transform(df_saldo_clus)\n",
    "\n",
    "#Compute DBSCAN\n",
    "_eps = 0.2\n",
    "_min_samp = 10\n",
    "db = OPTICS(min_samples=50, metric=\"euclidean\").fit(df_saldo_clus)\n",
    "\n",
    "#db = DBSCAN(eps=_eps, min_samples=_min_samp).fit(df_saldo_clus)\n",
    "labels = db.labels_\n",
    "df_saldo[\"ClusDb\"]=labels\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = list(labels).count(-1)\n",
    "\n",
    "# Print Result\n",
    "print('EPS: '+str( )+' & MinSamples: '+ str(_min_samp))\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print('Estimated number of noise points: %d' % n_noise)\n",
    "\"\"\"\n",
    "if n_clusters > 0:\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "    % metrics.silhouette_score(df_saldo_clus, labels))\n",
    "else:\n",
    "   print(\"Silhouette Coefficient: -\")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Data\n",
    "df_saldo_clus = df_saldo[[ \"Longitude\", \"Latitude\"]]\n",
    "df_saldo_clus = Standardscaler().fit_transform(df_saldo_clus)\n",
    "\n",
    "#Compute DBSCAN\n",
    "_eps = 0.2\n",
    "_min_samp = 10\n",
    "db = DBSCAN(eps=_eps, min_samples= _min_samp, n_jobs=-l).fit(saldo_df_clus)\n",
    "\n",
    "labels = db.labels_\n",
    "saldo_df[\"ClusterDBSCAN\"]=labels\n",
    "\n",
    "\n",
    "#Export cluster to CSV\n",
    "saldo_df.to_csv(\"DATA\\\\DBSCAN \"+str(_eps)+\" \"+str(_min_samp)+\".csv\" index=False)\n",
    "\n",
    "#Number of clusters in tabeLs, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "clusterNum = len (set(labels))\n",
    "n_noise_ = list(labels).count(-l)\n",
    "\n",
    "#Print cLusters, noise, siLhoette score, timestamp\n",
    "if n_clusters > 0:\n",
    "    print(str(_eps) + ',' + str(_min_samp) + ',' + str(n_clusters_)\n",
    "        + ',' +  str(n_noise_) + ','\n",
    "        + str(metrics.silhouette_score(saldo_df_clus, labels, metric=\"euclidean\",n_jobs=-l))\n",
    "        + str(datetime.datetime.now()) )\n",
    "else:\n",
    "\tprint(str(_eps) + ',' + str(_min_samp) + ',' + str(n_clusters_)\n",
    "\t    + str(n_noise_)\t+ ',' + str(datetime.datetime.now()) )  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import File\n",
    "saldo_df = pd.read_csv(\"DATA\\\\DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".csv\")      \n",
    "saldo_df = saldo_df.merge(pd.DataFrame({'CountReplenish':saldo_df.groupby(['MachineGroupCode', 'Longitude','Latitude','ClusterDBSCAN'])['MachineGroupCode'].count()}), left_on=['MachineGroupCode', 'Longitude','Latitude','ClusterDBSCAN'], right_index=True)\n",
    "saldo_df = saldo_df.drop('Id', 1)\n",
    "saldo_df = saldo_df.drop('DateReplenish', 1)\n",
    "saldo_df = saldo_df.drop('MachineCode', 1)\n",
    "saldo_df.drop_duplicates(subset=None, keep=\"first\", inplace=True)\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "#Create map\n",
    "my_map = Basemap(llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "    urcrnrlon=ulon, urcrnrlat=ulat)\n",
    "my_map.arcgisimage(service='World_Street_Map', xpixels = 3000)\n",
    "\n",
    "labels = saldo_df[\"ClusterDBSCAN\"].to_numpy()  \n",
    "realClusterNum=len(set(labels)) - (1 if -1 in labels else 0) \n",
    "unique_labels = set(labels)\n",
    "\n",
    "# Create color cluster\n",
    "colors = plt.get_cmap('hsv')(np.linspace(0.0, 1.0, len(unique_labels)))\n",
    "\n",
    "#Visualization\n",
    "for clust_number in unique_labels: \n",
    "    c = (([0.4,0.4,0.4]) if clust_number == -1 else colors[clust_number])\n",
    "    clust_set = saldo_df[saldo_df.ClusterDBSCAN == clust_number]  \n",
    "    my_map.scatter(clust_set.Longitude, clust_set.Latitude, color =c,  marker='o', s= (clust_set.CountReplenish /100) +3 ,alpha = 0.65)\n",
    "    \n",
    "    if clust_number != -1:\n",
    "        cenx=np.mean(clust_set.Longitude) \n",
    "        ceny=np.mean(clust_set.Latitude) \n",
    "        plt.text(cenx,ceny,str(clust_number), fontsize=3, color=c,\n",
    "                path_effects=[path_effects.withStroke(linewidth=0.3, foreground=\"w\")])\n",
    "\n",
    "#Save Image\n",
    "plt.title(r\"ATM's in Jakarta Clustered : EPS=\"+str(_eps)+\", MinSamples=\"+str(_min_samp), fontsize=14)        \n",
    "plt.savefig(\"VISUALIZATION\\\\DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".png\", dpi=400)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-28ab577051bb>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[0m_eps\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m0.2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[0m_min_samp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m10\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m \u001B[0mdb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mOPTICS\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmin_samples\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"euclidean\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_saldo_clus\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m#db = DBSCAN(eps=_eps, min_samples=_min_samp).fit(df_saldo_clus)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    257\u001B[0m              \u001B[0mleaf_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mleaf_size\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    258\u001B[0m              \u001B[0mmetric_params\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetric_params\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 259\u001B[1;33m              max_eps=self.max_eps)\n\u001B[0m\u001B[0;32m    260\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    261\u001B[0m         \u001B[1;31m# Extract clusters from the calculated orders and reachability\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001B[0m in \u001B[0;36mcompute_optics_graph\u001B[1;34m(X, min_samples, max_eps, metric, p, metric_params, algorithm, leaf_size, n_jobs)\u001B[0m\n\u001B[0;32m    496\u001B[0m                             \u001B[0mprocessed\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mprocessed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnbrs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mnbrs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    497\u001B[0m                             \u001B[0mmetric\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmetric_params\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmetric_params\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 498\u001B[1;33m                             p=p, max_eps=max_eps)\n\u001B[0m\u001B[0;32m    499\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mall\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misinf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mreachability_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    500\u001B[0m         warnings.warn(\"All reachability values are inf. Set a larger\"\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_optics.py\u001B[0m in \u001B[0;36m_set_reach_dist\u001B[1;34m(core_distances_, reachability_, predecessor_, point_index, processed, X, nbrs, metric, metric_params, p, max_eps)\u001B[0m\n\u001B[0;32m    529\u001B[0m             \u001B[1;31m# in the dict params\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    530\u001B[0m             \u001B[0m_params\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'p'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 531\u001B[1;33m         dists = pairwise_distances(P, np.take(X, unproc, axis=0),\n\u001B[0m\u001B[0;32m    532\u001B[0m                                    \u001B[0mmetric\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    533\u001B[0m                                    **_params).ravel()\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mtake\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36mtake\u001B[1;34m(a, indices, axis, out, mode)\u001B[0m\n\u001B[0;32m    192\u001B[0m            [5, 7]])\n\u001B[0;32m    193\u001B[0m     \"\"\"\n\u001B[1;32m--> 194\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_wrapfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'take'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mindices\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mout\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mout\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    195\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001B[0m in \u001B[0;36m_wrapfunc\u001B[1;34m(obj, method, *args, **kwds)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 61\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mbound\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     62\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m         \u001B[1;31m# A TypeError occurs if the object does have such a method in its\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#[3] Clustering DBSCAN \n",
    "\n",
    "#Get Data\n",
    "df_saldo_clus = df_saldo[[ \"Longitude\", \"Latitude\"]]\n",
    "df_saldo_clus = StandardScaler().fit_transform(df_saldo_clus)\n",
    "\n",
    "#Compute DBSCAN\n",
    "_eps = 0.2\n",
    "_min_samp = 10\n",
    "db = OPTICS(min_samples=50, metric=\"euclidean\").fit(df_saldo_clus)\n",
    "\n",
    "#db = DBSCAN(eps=_eps, min_samples=_min_samp).fit(df_saldo_clus)\n",
    "labels = db.labels_\n",
    "df_saldo[\"ClusDb\"]=labels\n",
    "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise = list(labels).count(-1)\n",
    "\n",
    "# Print Result\n",
    "print('EPS: '+str( )+' & MinSamples: '+ str(_min_samp))\n",
    "print('Estimated number of clusters: %d' % n_clusters)\n",
    "print('Estimated number of noise points: %d' % n_noise)\n",
    "\"\"\"\n",
    "if n_clusters > 0:\n",
    "    print(\"Silhouette Coefficient: %0.3f\"\n",
    "    % metrics.silhouette_score(df_saldo_clus, labels))\n",
    "else:\n",
    "   print(\"Silhouette Coefficient: -\")\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[4] Visualization \n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = (14,10)\n",
    "\n",
    "# Create map\n",
    "my_map = Basemap(llcrnrlon=llon, llcrnrlat=llat,urcrnrlon=ulon, urcrnrlat=ulat)\n",
    "my_map.arcgisimage(service='World_Street_Map', xpixels = 2000)\n",
    "\n",
    "# Create color cluster\n",
    "colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, n_clusters + 1))\n",
    "\n",
    "\n",
    "# Looping Cluster\n",
    "for clust_number in set(labels):\n",
    "    c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n",
    "    clust_set = df_saldo[df_saldo.ClusDb == clust_number]                    \n",
    "    my_map.scatter(clust_set.Longitude, clust_set.Latitude, color =c,  marker='o', s= 10, alpha = 0.65)\n",
    "    if clust_number != -1:\n",
    "        cenx=np.mean(clust_set.Longitude) \n",
    "        ceny=np.mean(clust_set.Latitude) \n",
    "        plt.text(cenx,ceny,str(clust_number), fontsize=30, color='red',)\n",
    "        print (\"Cluster \"+str(clust_number)+', Average Mean Debit Amount: '+ str(np.mean(clust_set.DebitAmount)))\n",
    "        print (\"Cluster \"+str(clust_number)+', Average Mean Count Replenish: '+ str(np.mean(clust_set.CountReplenish)))\n",
    "plt.title(r\"ATM di Jakarta Clustered: $ \\epsilon=\"+str(_eps)+\"$ MinSamples=\"+str(_min_samp), fontsize=14)        \n",
    "\n",
    "# Save Image\n",
    "plt.savefig(\"DBSCAN_VISUAL.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cmap(n, name='hsv'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "def ProsesDBSCAN(_eps, _min_samp):\n",
    "     # Import Library DBSCAN\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    import sklearn.utils\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    import matplotlib.patheffects as path_effects\n",
    "    saldo_df = pd.read_csv(\"DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".csv\") \n",
    "\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import rcParams\n",
    "    %matplotlib inline\n",
    "    rcParams['figure.figsize'] = (14,10)\n",
    "    my_map = Basemap(llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "        urcrnrlon=ulon, urcrnrlat=ulat)\n",
    "    my_map.arcgisimage(service='World_Street_Map', xpixels = 3000)\n",
    "\n",
    "    \n",
    "    labels = saldo_df[\"ClusterDBSCAN\"].to_numpy()  \n",
    "    \n",
    "    realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    clusterNum = len(set(labels)) \n",
    "\n",
    "    # To create a color map\n",
    "    colors = plt.get_cmap('hsv')(np.linspace(0.0, 1.0, clusterNum))\n",
    "         \n",
    "    #Visualization1\n",
    "    for clust_number in set(labels):\n",
    "        c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n",
    "        #c1 = (([0.4,0.4,0.4]) if clust_number == -1 else get_cmap(clust_number))\n",
    "        clust_set = saldo_df[saldo_df.ClusterDBSCAN == clust_number]                    \n",
    "        my_map.scatter(clust_set.Longitude, clust_set.Latitude, color =c,  marker='o', s= 5, alpha = 0.65)\n",
    "        if clust_number != -1:\n",
    "            cenx=np.mean(clust_set.Longitude) \n",
    "            ceny=np.mean(clust_set.Latitude) \n",
    "            plt.text(cenx,ceny,str(clust_number), fontsize=3, color=c,\n",
    "                    path_effects=[path_effects.withStroke(linewidth=0.5, foreground=\"w\")])\n",
    "            #print (\"Cluster \"+str(clust_number)+', Average Mean Debit Amount: '+ str(np.mean(clust_set.DebitAmount)))\n",
    "            #print (\"Cluster \"+str(clust_number)+', Average Mean Count Replenish: '+ str(np.mean(clust_set.CountReplenish)))\n",
    "    plt.title(r\"ATM's in Jakarta Clustered : EPS=\"+str(_eps)+\" MinSamples=\"+str(_min_samp), fontsize=14)        \n",
    "    plt.savefig(\"DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".png\", dpi=400)\n",
    "    \n",
    "ProsesDBSCAN(0.01,50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.get_cmap('hsv')(np.linspace(0.0, 1.0, 1100))\n",
    "df = pd.DataFrame(data=colors)\n",
    "print(colors)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_cmap(nlabels, type='soft', first_color_black=True, last_color_black=False, verbose=True):\n",
    "    \"\"\"\n",
    "    Creates a random colormap to be used together with matplotlib. Useful for segmentation tasks\n",
    "    :param nlabels: Number of labels (size of colormap)\n",
    "    :param type: 'bright' for strong colors, 'soft' for pastel colors\n",
    "    :param first_color_black: Option to use first color as black, True or False\n",
    "    :param last_color_black: Option to use last color as black, True or False\n",
    "    :param verbose: Prints the number of labels and shows the colormap. True or False\n",
    "    :return: colormap for matplotlib\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    import colorsys\n",
    "    import numpy as np\n",
    "\n",
    "\n",
    "    if type not in ('bright', 'soft'):\n",
    "        print ('Please choose \"bright\" or \"soft\" for type')\n",
    "        return\n",
    "\n",
    "    if verbose:\n",
    "        print('Number of labels: ' + str(nlabels))\n",
    "\n",
    "    # Generate color map for bright colors, based on hsv\n",
    "    if type == 'bright':\n",
    "        randHSVcolors = [(np.random.uniform(low=0.0, high=1),\n",
    "                          np.random.uniform(low=0.2, high=1),\n",
    "                          np.random.uniform(low=0.9, high=1)) for i in range(nlabels)]\n",
    "\n",
    "        # Convert HSV list to RGB\n",
    "        randRGBcolors = []\n",
    "        for HSVcolor in randHSVcolors:\n",
    "            randRGBcolors.append(colorsys.hsv_to_rgb(HSVcolor[0], HSVcolor[1], HSVcolor[2]))\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Generate soft pastel colors, by limiting the RGB spectrum\n",
    "    if type == 'soft':\n",
    "        low = 0.6\n",
    "        high = 0.95\n",
    "        randRGBcolors = [(np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high),\n",
    "                          np.random.uniform(low=low, high=high)) for i in range(nlabels)]\n",
    "\n",
    "        if first_color_black:\n",
    "            randRGBcolors[0] = [0, 0, 0]\n",
    "\n",
    "        if last_color_black:\n",
    "            randRGBcolors[-1] = [0, 0, 0]\n",
    "        random_colormap = LinearSegmentedColormap.from_list('new_map', randRGBcolors, N=nlabels)\n",
    "\n",
    "    # Display colorbar\n",
    "    if verbose:\n",
    "        from matplotlib import colors, colorbar\n",
    "        from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 0.5))\n",
    "\n",
    "        bounds = np.linspace(0, nlabels, nlabels + 1)\n",
    "        norm = colors.BoundaryNorm(bounds, nlabels)\n",
    "\n",
    "        cb = colorbar.ColorbarBase(ax, cmap=random_colormap, norm=norm, spacing='proportional', ticks=None,\n",
    "                                   boundaries=bounds, format='%1i', orientation=u'horizontal')\n",
    "\n",
    "    return random_colormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VisualisasiDBSCAN(_eps, _min_samp):\n",
    "     # Import Library DBSCAN\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "        \n",
    "    from sklearn.cluster import DBSCAN\n",
    "    import sklearn.utils\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    import matplotlib.patheffects as path_effects\n",
    "    saldo_df = pd.read_csv(\"DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".csv\") \n",
    "\n",
    "    from mpl_toolkits.basemap import Basemap\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pylab import rcParams\n",
    "    %matplotlib inline\n",
    "    rcParams['figure.figsize'] = (14,10)\n",
    "    my_map = Basemap(llcrnrlon=llon, llcrnrlat=llat, #min longitude (llcrnrlon) and latitude (llcrnrlat)\n",
    "        urcrnrlon=ulon, urcrnrlat=ulat)\n",
    "    my_map.arcgisimage(service='World_Street_Map', xpixels = 3000)\n",
    "\n",
    "    \n",
    "    labels = saldo_df[\"ClusterDBSCAN\"].to_numpy()  \n",
    "    \n",
    "    realClusterNum=len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    clusterNum = len(set(labels)) \n",
    "    colors = ['royalblue', 'maroon', 'forestgreen', 'mediumorchid', 'tan', 'deeppink', 'olive', 'goldenrod', 'lightcyan', 'navy']\n",
    "    vectorizer = np.vectorize(lambda x: colors[x % len(colors)])\n",
    "    # To create a color map\n",
    "    colors = plt.get_cmap('jet')(np.linspace(0.0, 1.0, clusterNum))\n",
    "    \n",
    "    \n",
    "    coloor = rand_cmap(clusterNum, type='soft', first_color_black=True, last_color_black=False, verbose=True)\n",
    "    #Visualization1\n",
    "    for clust_number in set(labels):\n",
    "        #c=(([0.4,0.4,0.4]) if clust_number == -1 else colors[np.int(clust_number)])\n",
    "        c = (([0.4,0.4,0.4]) if clust_number == -1 else coloor(clust_number)[:3])\n",
    "        clust_set = saldo_df[saldo_df.ClusterDBSCAN == clust_number]                    \n",
    "        my_map.scatter(clust_set.Longitude, clust_set.Latitude, color=c,  marker='o', s= 5, alpha = 0.65)\n",
    "        if clust_number != -1:\n",
    "            cenx=np.mean(clust_set.Longitude) \n",
    "            ceny=np.mean(clust_set.Latitude) \n",
    "            #plt.text(cenx,ceny,str(clust_number), fontsize=3, color=c,\n",
    "            #        path_effects=[path_effects.withStroke(linewidth=0.5, foreground=\"w\")])\n",
    "    plt.title(r\"ATM's in Jakarta Clustered : EPS=\"+str(_eps)+\" MinSamples=\"+str(_min_samp), fontsize=14)        \n",
    "    plt.savefig(\"VISUALIZATION\\\\DBSCAN_\"+str(_eps)+\"_\"+str(_min_samp)+\".png\", dpi=400)\n",
    "     \n",
    "VisualisasiDBSCAN(0.01,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}